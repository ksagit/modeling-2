{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/kylesargent/Dropbox/evlab/modeling 2/')\n",
    "from dat import Dat\n",
    "data = Dat()\n",
    "data.add_dict('twitter')\n",
    "data.make_gen_dict()\n",
    "X,y = data.getXy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f2bcb355ecdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mframe_dist_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mframe_dist_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-f2bcb355ecdc>\u001b[0m in \u001b[0;36mjd\u001b[0;34m(v, w)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mci\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcj\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcij\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def jd(v,w): \n",
    "    ci  = np.sum(v)\n",
    "    cj  = np.sum(w)\n",
    "    cij = np.sum((v + w)//2)\n",
    "    if cij == 0:\n",
    "        return(1)\n",
    "    else:\n",
    "        return(1 - (cij)/(ci + cj - cij))\n",
    "    \n",
    "def cs(v,w):\n",
    "    return(cosine_similarity([v], [w])[0][0])\n",
    "    \n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "n_frames = y.shape[1]\n",
    "frame_dist_matrix = np.zeros((n_frames, n_frames))\n",
    "for i in range(0, n_frames):\n",
    "    for j in range(i, n_frames):\n",
    "        d = jd(y[:,i],y[:,j])\n",
    "        frame_dist_matrix[i][j] = d\n",
    "        frame_dist_matrix[j][i] = d\n",
    "        \n",
    "n_verbs = y.shape[0]\n",
    "verb_syntax_dist_matrix = np.zeros((n_verbs, n_verbs))\n",
    "for i in range(0, n_verbs):\n",
    "    for j in range(i, n_verbs):\n",
    "        d = jd(y[i],y[j])\n",
    "        verb_syntax_dist_matrix[i][j] = d\n",
    "        verb_syntax_dist_matrix[j][i] = d\n",
    "        \n",
    "verb_cossim_dist_matrix = np.zeros((n_verbs, n_verbs))\n",
    "for i in range(0, n_verbs):\n",
    "    for j in range(i, n_verbs):\n",
    "        d = cs(X[i],X[j])\n",
    "        verb_cossim_dist_matrix[i][j] = d\n",
    "        verb_cossim_dist_matrix[j][i] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "scipy.io.savemat('fsd.mat', mdict={'frame_syntax_distance': frame_dist_matrix})\n",
    "scipy.io.savemat('vsd.mat', mdict={'verb_syntax_distance': verb_syntax_dist_matrix})\n",
    "scipy.io.savemat('vcd.mat', mdict={'verb_cossim_distance': verb_cossim_dist_matrix})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "frame_cluster_labels = np.array(scipy.io.loadmat(\"cluster_labels.mat\")[\"fcl\"]).T[0]\n",
    "verb_syntax_cluster_labels = np.array(scipy.io.loadmat(\"cluster_labels.mat\")[\"vscl\"]).T[0]\n",
    "verb_cossim_cluster_labels = np.array(scipy.io.loadmat(\"cluster_labels.mat\")[\"vccl\"]).T[0]\n",
    "\n",
    "from sklearn.metrics import adjusted_mutual_info_score as ami\n",
    "\n",
    "print(max(verb_syntax_cluster_labels))    \n",
    "print(max(verb_cossim_cluster_labels))\n",
    "#np.mean(ami_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determing list of diagnostic frames, \n",
    "        \n",
    "\n",
    "        \n",
    "aff = np.exp(- frame_dist_matrix ** 2 / (2. * 1 ** 2)) #Gaussian heat kernel\n",
    "\n",
    "n_diagnostic_frames = 50\n",
    "\n",
    "sc_frames = SpectralClustering(n_clusters = n_diagnostic_frames, affinity = \"precomputed\")\n",
    "frame_cluster_predictions = sc_frames.fit_predict(aff)\n",
    "frame_cluster_pairs = list(enumerate(frame_cluster_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "glove_verbs = list(map(lambda v : (v[0]), list(gen_dict.items())))\n",
    "glove_vecs = np.array(list(map(lambda v : (v[1][1]), list(gen_dict.items()))))\n",
    "\n",
    "n_diagnostic_verbs = 100\n",
    "\n",
    "kmc_verbs = KMeans(n_clusters = n_diagnostic_verbs)\n",
    "verb_cluster_predictions = kmc_verbs.fit_predict(glove_vecs)\n",
    "\n",
    "verb_cluster_pairs = list(enumerate(verb_cluster_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_sample(l, n_clusters):\n",
    "    res = []\n",
    "    random.shuffle(l)\n",
    "    for i in range(0, n_clusters):\n",
    "        for v,c in l:\n",
    "            if i == c:\n",
    "                bv = v\n",
    "        res += [bv]\n",
    "    return(res)\n",
    "        \n",
    "import pandas as pd\n",
    "\n",
    "def maketable():\n",
    "    diagnostic_verb_list = [glove_verbs[i] for i in cluster_sample(verb_cluster_pairs, n_diagnostic_verbs)]\n",
    "    diagnostic_frame_list = [frame_list[i] for i in cluster_sample(frame_cluster_pairs, n_diagnostic_frames)]\n",
    "\n",
    "    if len(diagnostic_verb_list) - len(list(set(diagnostic_verb_list))) > 0:\n",
    "        return(maketable())\n",
    "    elif len(diagnostic_frame_list) - len(list(set(diagnostic_frame_list))) > 0:\n",
    "        return(maketable())\n",
    "    else:\n",
    "        data = np.zeros((n_diagnostic_verbs, n_diagnostic_frames))\n",
    "        for i in range(0, n_diagnostic_verbs):\n",
    "            for j in range(0, n_diagnostic_frames):\n",
    "                data[i][j] = verbnet_dict[diagnostic_verb_list[i]][ frame_list.index(diagnostic_frame_list[j]) ]\n",
    "\n",
    "        df = pd.DataFrame(data, index = diagnostic_verb_list, columns = diagnostic_frame_list, dtype=int)\n",
    "\n",
    "\n",
    "        for i in range(0, n_diagnostic_verbs//2):\n",
    "            verb = pd.Series.argmin(df.sum(axis=1))\n",
    "            df = df.drop(verb, axis=0)\n",
    "\n",
    "        for i in range(0, n_diagnostic_frames//2):\n",
    "            frame = pd.Series.argmin(df.sum(axis=0))\n",
    "            df = df.drop(frame, axis=1)\n",
    "\n",
    "        return(df)\n",
    "\n",
    "btable = maketable()\n",
    "bcount = pd.DataFrame.sum(df.sum(axis=0))\n",
    "for i in range(0, 100):\n",
    "    t = maketable()\n",
    "    count = pd.DataFrame.sum(t.sum(axis=0))\n",
    "    if count > bcount:\n",
    "        btable = t\n",
    "        bcount = count\n",
    "df = btable\n",
    "\n",
    "print(\"Sparsity = \", pd.DataFrame.sum(df.sum(axis=0)) / (n_diagnostic_frames//2 * n_diagnostic_verbs//2))\n",
    "print(\"Size =\", df.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
