{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/kylesargent/Dropbox/evlab/modeling 2/')\n",
    "from dat import Dat\n",
    "data = Dat()\n",
    "data.add_dict('twitter')\n",
    "data.make_gen_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good shuffle found!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "X,y_sparse = data.getXy()\n",
    "\n",
    "def shuffle(a, b): \n",
    "    p = np.random.permutation(len(a))\n",
    "    return(a[p], b[p])\n",
    "\n",
    "l = round(.8 * len(X))\n",
    "\n",
    "#random.shuffle(y_sparse)\n",
    "\n",
    "sparse_frames = [i for (i,j) in enumerate(np.sum(y_sparse, axis=0)) if j < 500]\n",
    "y = np.delete(y_sparse, sparse_frames,axis=1)\n",
    "rich_frame_list = np.delete(data.frame_list + [\"\"], sparse_frames, axis=0)\n",
    "\n",
    "m = 0\n",
    "while (m == 0):\n",
    "    X,y = shuffle(X,y)\n",
    "    y_train = y[:l]\n",
    "    y_validation = y[l:]\n",
    "    m = min(min(np.sum(y_train, axis=0)), min(np.sum(y_validation, axis=0)))\n",
    "\n",
    "X_train = np.array(X[:l])\n",
    "X_validation = np.array(X[l:])\n",
    "\n",
    "print(\"Good shuffle found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0407256979722\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "\n",
    "def jd(v,w):\n",
    "    return(1 - jaccard_similarity_score(np.array([v]), np.array([w])))\n",
    "    \n",
    "def cs(v,w):\n",
    "    return((cosine_similarity([v], [w])[0][0]))\n",
    "\n",
    "def ed(v,w):\n",
    "    return(np.linalg.norm(v - w))\n",
    "\n",
    "X_2 = np.dot(X, (pca.components_).T)\n",
    "\n",
    "css = []\n",
    "jds = []\n",
    "y_pred = lr.predict(X)\n",
    "for _i in range(0, 10000):\n",
    "    s1,s2 = np.random.randint(len(X)), np.random.randint(len(X))\n",
    "    x1,x2 = X[s1], X[s2]\n",
    "    y1,y2 = y[s1], y[s2]   \n",
    "    c = ed(x1,x2)\n",
    "    j = jd(y1,y2)\n",
    "    css += [c]\n",
    "    jds += [j]\n",
    "\n",
    "plt.clf()\n",
    "plt.xlabel(\"GLoVe cosine similarity\")\n",
    "plt.ylabel(\"VerbNet frame Jaccard Distance\")\n",
    "plt.scatter(css, jds)\n",
    "plt.savefig(\"GloVe_sim_vs_VerbNet_sim.png\")\n",
    "\n",
    "print(np.corrcoef(jds, css)[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "total = 0\n",
    "for i in range(0,1000):\n",
    "    a = np.random.choice(range(0,183))\n",
    "    b = np.random.choice(range(0,183))\n",
    "\n",
    "    total += np.abs(jd2(y[:,a], y[:,b]) - jd(y[:,a], y[:,b]))\n",
    "    \n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.718283839946\n",
      "0.718283839946\n",
      "46.8234501348\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import coverage_error\n",
    "\n",
    "y_pred = lr_transformed.predict_proba(X_validation_2)\n",
    "print(roc_auc_score(y_validation, y_pred, average='macro'))\n",
    "print(avg_auc(y_pred, y_validation))\n",
    "print(coverage_error(y_validation, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lr = OneVsRestClassifier(LogisticRegression())\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.],\n",
       "       [ 1.,  1.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef([-1,1], [-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reorienting GLoVe axis before learning\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "syntaxspace_learner = OneVsRestClassifier(LogisticRegression())\n",
    "syntaxspace_learner.fit(X_train, y_train)\n",
    "\n",
    "w = np.array((list(map(lambda x : (x.coef_[0]), syntaxspace_learner.estimators_))))\n",
    "\n",
    "pca = PCA(n_components = 5)\n",
    "pca.fit(w)\n",
    "\n",
    "X_train_2 = np.dot(X_train, (pca.components_).T)\n",
    "X_validation_2 = np.dot(X_validation, (pca.components_).T)\n",
    "\n",
    "lr_transformed = OneVsRestClassifier(LogisticRegression())\n",
    "lr_transformed.fit(X_train_2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.718283839946\n",
      "0.807820820977\n"
     ]
    }
   ],
   "source": [
    "proba_transformed = lr_transformed.predict_proba(X_validation_2)\n",
    "proba_full = lr.predict_proba(X_validation)\n",
    "\n",
    "print(avg_auc(proba_transformed, y_validation))\n",
    "print(avg_auc(proba_full, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auc_list = []\n",
    "for i in range(1, 100):\n",
    "    X_train_2 = np.dot(X_train, (pca.components_[:i+1]).T)\n",
    "    X_validation_2 = np.dot(X_validation, (pca.components_[:i+1]).T)\n",
    "\n",
    "    lr_transformed = OneVsRestClassifier(LogisticRegression())\n",
    "    lr_transformed.fit(X_train_2, y_train)\n",
    "    \n",
    "    proba_transformed = lr_transformed.predict_proba(X_validation_2)\n",
    "    c = avg_auc(proba_transformed, y_validation)\n",
    "    auc_list += [c]\n",
    "    print(c)\n",
    "    \n",
    "plt.clf()\n",
    "plt.xlabel(\"Number of dimensions\")\n",
    "plt.ylabel(\"Average AUC value\")\n",
    "plt.scatter(np.array(list(range(0,100))) + 1, np.array(auc_list), s=5)\n",
    "\n",
    "plt.plot([1,100], [0.831640174862,0.831640174862])\n",
    "plt.plot([1,100], [0.5,0.5])\n",
    "\n",
    "plt.savefig(\"aucbydimension.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Benchmarks for MLC predictor that gives var pred_probas, judged against true var labels\n",
    "\n",
    "def avg_auc(pred_probas, labels):\n",
    "    ras = []\n",
    "    for i in range(0, labels.shape[1]):\n",
    "        y_true = labels[:,i]\n",
    "        y_pred = pred_probas[:,i]\n",
    "        ras += [roc_auc_score(y_true, y_pred)]\n",
    "    return(np.mean(ras))\n",
    "\n",
    "def auc_scatter(pred_probas, labels):\n",
    "    aucs = []\n",
    "    texps = []\n",
    "    for i in range(0, labels.shape[1]):\n",
    "        texps += [np.sum(labels, axis=0)[i]]\n",
    "        aucs += [roc_auc_score(labels[:,i], pred_probas[:,i])]\n",
    "    plt.clf()\n",
    "    plt.xlabel(\"Number of positive training examples\")\n",
    "    plt.ylabel(\"AUROC value\")\n",
    "    plt.scatter(texps, aucs, s=5)\n",
    "            \n",
    "def auc_plot(pred_probas, labels, threshold):\n",
    "    plt.clf()\n",
    "    ras = []\n",
    "    for i in range(0, labels.shape[1]):\n",
    "        y_true = labels[:,i]\n",
    "        y_score = pred_probas[:,i]\n",
    "        if np.sum(y[:,i]) >= threshold:\n",
    "            fpr = roc_curve(y_true, y_score)[0]\n",
    "            tpr = roc_curve(y_true, y_score)[1]\n",
    "            plt.plot(fpr, tpr)\n",
    "            ras += [roc_auc_score(y_true, y_score)]\n",
    "    plt.plot([0,1], [0,1])\n",
    "    \n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Avg AUC = \"+ str(np.mean(ras))+ \" with threshold=\"+ str(threshold))\n",
    "    \n",
    "def plots(threshold_list):\n",
    "    for i in threshold_list:\n",
    "        auc_plot(probs, i)\n",
    "        plt.savefig(\"auc_plot\" + str(i) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating MatLab-compatible data\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "train_data = X_train #(X_train - X_train.min(0)) / X_train.ptp(0)\n",
    "train_target = (2 * y_train - 1).T\n",
    "\n",
    "test_data = X_validation #(X_validation - X_validation.min(0)) / X_validation.ptp(0)\n",
    "test_target = (2 * y_validation - 1).T\n",
    "\n",
    "scipy.io.savemat('train_data.mat', mdict={'train_data': train_data})\n",
    "scipy.io.savemat('train_target.mat', mdict={'train_target': train_target})\n",
    "scipy.io.savemat('test_data.mat', mdict={'test_data': test_data})\n",
    "scipy.io.savemat('test_target.mat', mdict={'test_target': test_target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BPMLL_predict_proba = .5 * (scipy.io.loadmat(\"Outputs.mat\")[\"Outputs\"].T + 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
